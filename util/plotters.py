import os

import matplotlib.axes
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from util.data_constants import GEN

d_loss = 'd_loss'
g_loss = 'g_loss'


def plot_data_distr(path, compare_column=None):
    if compare_column is None:
        compare_column = 'Dur'
    df = pd.read_csv(path)
    df.dropna(inplace=True)
    df.replace({'*': ''})

    # plt.figure()
    # fig, axs = plt.subplots(2, 1, figsize=(10, 8))
    # fig = plt.figure(figsize=(7,3))

    x0 = 2**5
    x1 = 2**15

    # ax = df[compare_column].plot.kde(bw_method=0.01, label='Normal', color='tab:blue')
    fig = sns.kdeplot(df['SrcBytes'], bw_method=0.01, fill=True, alpha=.5, log_scale=2)
    fig.set_xlabel("bytes")
    p2 = plt.axvline(x=x1, color='#EF9A9A')

    xlim = fig.get_xlim()
    fig.axvspan(x1, xlim[1], color='#EF9A9A', alpha=0.3)
    # kde_x, kde_y = fig.lines[0].get_data()
    # fig.fill_between(kde_x, kde_y, where=(kde_x < x0) | (kde_x > x1),
    #                 interpolate=True, color='#EF9A9A')
    # plt.text(2, 1, "An annotation", horizontalalignment='left', size='medium', color='black', weight='semibold')
    # axs[0].arrow(.1, overhang, .6, 0, width=0.001, color="k",
    #          head_width=0.1, head_length=0.15, overhang=overhang)
    # fig.tight_layout()
    plt.title(f'Density of SrcBytes')
    plt.gcf().set_size_inches(6, 3)
    plt.show()


def plot_learning_curve(path):
    df = pd.read_csv(path)
    plt.plot(df[d_loss], label=d_loss)
    plt.plot(df[g_loss], label=g_loss)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Loss function in epochs')
    plt.show()


def plot_distribution(path1, path2, compare_column=None):
    if compare_column is None:
        compare_column = ['Dur']
    df1 = pd.read_csv(path1)
    df2 = pd.read_csv(path2)

    fig = plt.figure(figsize=(10, 15))
    fig.suptitle(f'Anomaly={os.path.basename(path1)}', fontsize=16)
    for idx, item in enumerate(compare_column):
        ax1 = fig.add_subplot(len(compare_column), 1, idx + 1)
        df2[item].plot.kde(bw_method=0.05, ax=ax1, label='Normal', color='tab:blue')
        xlim = ax1.get_xlim()
        ax2 = ax1.twinx()
        df1[item].plot.kde(bw_method=0.05, ax=ax2, label='Anomaly', color='tab:red')
        ax2.set_xlim(xlim)

        ax1.plot()
        ax2.plot()
        ax1.legend()
        ax2.legend(loc='upper left')
        ax1.title.set_text(f'Density of {item}')
    fig.tight_layout()
    plt.show()
    print('k')


def plot_distribution2(path1, path2, compare_column=None):
    if compare_column is None:
        compare_column = ['Dur']
    df1 = pd.read_csv(path1)
    df2 = pd.read_csv(path2)

    df1.dropna(inplace=True)
    df2.dropna(inplace=True)

    def clean(serie):
        output = serie[(np.isnan(serie) == False) & (np.isinf(serie) == False)]
        return output

    fig, axs = plt.subplots(len(compare_column), 1, figsize=(10, 15))
    fig.suptitle(f'Anomaly={os.path.basename(path1)}', fontsize=16)
    for idx, item in enumerate(compare_column):
        # ax1 = fig.add_subplot(len(compare_column), 1, idx + 1)
        # xlim = ax1.get_xlim()
        # ax2 = ax1.twinx()
        # ax2.set_xlim(xlim)
        data = pd.DataFrame({
            'Normal': clean(df2[item]),
            'Anomaly': clean(df1[item])
        })
        sns.kdeplot(data=data, bw_method=0.05, ax=axs[idx], multiple="stack", alpha=.5)
        axs[idx].title.set_text(f'Density of {item}')
        # sns.violinplot(data=data, split=True, bw_method=0.01, ax=axs[idx], orient='h', hue='Normal', x=[])
        # sns.kdeplot(, bw_method=0.04, ax=axs[idx])
        # ax1.plot()
        # ax2.plot()
        # ax1.legend()
        # ax2.legend(loc='upper left')
        # ax1.title.set_text(f'Density of {item}')
    fig.tight_layout()
    plt.show()
    print('k')


def plot_corr_heatmap(path):
    df = pd.read_csv(path)
    df = df.reindex(sorted(df.columns), axis=1)

    plt.figure(figsize=(15, 10))
    heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)
    heatmap.set_title('Correlation Heatmap', fontdict={'fontsize': 12}, pad=12)
    plt.show()


def plot_corr_heatmap_difference(path1, path2):
    df1 = pd.read_csv(path1)
    df1 = df1.reindex(sorted(df1.columns), axis=1)

    df2 = pd.read_csv(path2)
    df2 = df2.reindex(sorted(df2.columns), axis=1)

    corr = df1.corr() - df2.corr()

    plt.figure(figsize=(15, 10))
    heatmap = sns.heatmap(corr, vmin=-1, vmax=1, annot=True)
    heatmap.set_title(f'Difference between correlation heatmaps '
                      f'({os.path.splitext(os.path.basename(path1))[0]} -'
                      f' {os.path.splitext(os.path.basename(path2))[0]})',
                      fontdict={'fontsize': 12}, pad=12)
    plt.show()


if __name__ == '__main__':
    DATA_CSV_PATH = '..\\saved_data\\custom_data\\p2_spotify_cont_prepared_v1.csv'
    cols = [
        'StartTime',
        'Dur',
        'sTos',
        'dTos',
        'SrcBytes',
        'DstBytes',
        # 'SrcLoad',
        # 'DstLoad',
        # 'SrcRate',
        # 'DstRate',
        'SrcPkts',
        'DstPkts',
        # 'daytime'
    ]
    # DATA_PATH = f'..\\saved_data\\wgan_{GEN}_data_generated_2_cols.csv'
    DATA_PATH = f'..\\saved_data\\wgan_GEN_52_data_generated_0_cols.csv'

    # plot_learning_curve('..\\saved_data\\learning_logs\\wgan_pg_100_01.log')

    plot_distribution(DATA_PATH,
                      '..\\saved_data\\custom_data2\\p2_spotify_gen3_prepared.csv',
                      cols)

    plot_distribution2(DATA_PATH,
                      '..\\saved_data\\custom_data2\\p2_spotify_gen3_prepared.csv',
                      cols)

    plot_corr_heatmap(DATA_PATH)
    # plot_corr_heatmap(DATA_CSV_PATH)

    plot_corr_heatmap_difference('..\\saved_data\\custom_data2\\p2_spotify_gen3_prepared.csv',
                                 DATA_PATH)

    # plot_data_distr('..\\saved_data\\custom_data2\\p2_spotify_gen3.csv', compare_column='SrcBytes')
