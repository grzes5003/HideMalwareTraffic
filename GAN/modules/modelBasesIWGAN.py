import itertools

import tensorflow as tf
from keras import backend as K
from tensorflow.keras import layers
from tensorflow.python.framework import ops
from keras.utils.generic_utils import get_custom_objects
from GAN.modules.modelBases import upsample_block


noise_dim = 160
DATA_INPUT1 = (2, 1)
DATA_INPUT2 = (156, 1)


def conv_block(
    x,
    filters,
    activation,
    kernel_size=(3),
    strides=(1),
    padding="same",
    use_bias=True,
    use_bn=False,
    use_dropout=False,
    drop_value=0.5,
    name=None
):
    if name is not None:
        x = layers.Conv1D(
            filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias, name=name
        )(x)
    else:
        x = layers.Conv1D(
            filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias
        )(x)
    if use_bn:
        x = layers.BatchNormalization()(x)
    x = activation(x)
    if use_dropout:
        x = layers.Dropout(drop_value)(x)
    return x


class GeneratorBaseIWGAN:
    @staticmethod
    def get_generator_model():
        noise = layers.Input(shape=(noise_dim,))

        l1 = layers.Dense(2 * 5, use_bias=False)(noise)
        l1 = layers.BatchNormalization()(l1)
        l1 = layers.LeakyReLU(0.1)(l1)
        l1 = layers.Dense(15)(l1)
        l1 = layers.Dense(10)(l1)
        l1 = layers.Dense(2)(l1)
        l1 = layers.Activation('sigmoid')(l1)
        l1 = layers.Reshape(DATA_INPUT1)(l1)

        l2 = layers.Dense(13 * 10, use_bias=False)(noise)
        l2 = layers.BatchNormalization()(l2)
        l2 = layers.LeakyReLU(0.2)(l2)

        l2 = layers.Reshape((13, 10))(l2)
        l2 = upsample_block(
            l2,
            20,
            layers.LeakyReLU(0.2),
            strides=(2),
            # up_size=4,
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        l2 = upsample_block(
            l2,
            12,
            layers.LeakyReLU(0.2),
            strides=(2),
            # up_size=4,
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )

        l2 = layers.Flatten()(l2)
        l2 = layers.Activation('sigmoid')(l2)
        l2 = layers.Reshape(DATA_INPUT2)(l2)
        # At this point, we have an output which has the same shape as the input, (32, 32, 1).
        # We will use a Cropping2D layer to make it (28, 28, 1).
        # x = layers.Cropping1D(1)(x)

        g_model = tf.keras.models.Model(noise, (l1, l2), name="generator")
        return g_model


class DiscriminatorBaseIWGAN:
    @staticmethod
    def get_discriminator_model():
        data_input1 = layers.Input(shape=DATA_INPUT1)
        data_input2 = layers.Input(shape=DATA_INPUT2)

        # l1 = conv_block(
        #     data_input1,
        #     16,
        #     kernel_size=5,
        #     strides=2,
        #     use_bn=False,
        #     use_bias=True,
        #     activation=layers.LeakyReLU(0.2),
        #     use_dropout=False,
        #     drop_value=0.3,
        #     name='l1_conv1'
        # )
        # l1 = conv_block(
        #     l1,
        #     8,
        #     kernel_size=5,
        #     strides=2,
        #     use_bn=False,
        #     use_bias=True,
        #     activation=layers.LeakyReLU(0.2),
        #     use_dropout=False,
        #     drop_value=0.3,
        #     name='l1_conv2'
        # )

        l1 = layers.Dense(10)(data_input1)
        l1 = layers.Dense(8)(l1)
        # l1 = layers.Dense(10)(l1)

        l2 = conv_block(
            data_input2,
            32,
            kernel_size=5,
            strides=2,
            use_bn=False,
            use_bias=True,
            activation=layers.LeakyReLU(0.2),
            use_dropout=False,
            drop_value=0.3,
            name='l2_conv1'
        )
        l2 = conv_block(
            l2,
            16,
            kernel_size=5,
            strides=3,
            use_bn=False,
            use_bias=True,
            activation=layers.LeakyReLU(0.2),
            use_dropout=False,
            drop_value=0.3,
            name='l2_conv2'
        )
        l2 = conv_block(
            l2,
            8,
            kernel_size=5,
            strides=4,
            use_bn=False,
            use_bias=True,
            activation=layers.LeakyReLU(0.2),
            use_dropout=False,
            drop_value=0.3,
            name='l2_conv3'
        )

        x = layers.Concatenate(axis=1)([l1, l2])

        x = layers.Flatten()(x)
        x = layers.Dropout(0.3)(x)
        x = layers.Dense(1, name='dense1')(x)
        # x = layers.Activation('softmax')(x)

        d_model = tf.keras.models.Model([data_input1, data_input2], x, name="discriminator")
        return d_model
