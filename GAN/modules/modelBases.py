import tensorflow as tf
from tensorflow.keras import layers
from util.initializer import initializer


def conv_block(
    x,
    filters,
    activation,
    kernel_size=(3),
    strides=(1),
    padding="same",
    use_bias=True,
    use_bn=False,
    use_dropout=False,
    drop_value=0.5,
):
    x = layers.Conv1D(
        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias
    )(x)
    if use_bn:
        x = layers.BatchNormalization()(x)
    x = activation(x)
    if use_dropout:
        x = layers.Dropout(drop_value)(x)
    return x


def dense_block(
    x,
    filters,
    activation,
    use_bias=True,
    use_bn=False,
    use_dropout=False,
    drop_value=0.5,
):
    x = layers.Dense(
        filters, use_bias=use_bias
    )(x)
    if use_bn:
        x = layers.BatchNormalization()(x)
    x = activation(x)
    if use_dropout:
        x = layers.Dropout(drop_value)(x)
    return x


def upsample_block(
    x,
    filters,
    activation,
    kernel_size=(3),
    strides=(1),
    up_size=(2),
    padding="same",
    use_bn=False,
    use_bias=True,
    use_dropout=False,
    drop_value=0.3,
):
    x = layers.UpSampling1D(up_size)(x)
    x = layers.Conv1D(
        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias
    )(x)

    if use_bn:
        x = layers.BatchNormalization()(x)

    if activation:
        x = activation(x)
    if use_dropout:
        x = layers.Dropout(drop_value)(x)
    return x


def upsample_dense_block(
        x,
        filters,
        activation,
        up_size=(2),
        use_bn=False,
        use_bias=True,
        use_dropout=False,
        drop_value=0.3,
):
    # x = layers.UpSampling1D(up_size)(x)
    x = layers.Dense(
        filters, use_bias=use_bias
    )(x)

    if use_bn:
        x = layers.BatchNormalization()(x)

    if activation:
        x = activation(x)
    if use_dropout:
        x = layers.Dropout(drop_value)(x)
    return x


noise_dim = 32


class GeneratorBase:
    @staticmethod
    def get_generator_model():
        noise = layers.Input(shape=(noise_dim,))
        x = layers.Dense(4 * 256, use_bias=False)(noise)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.2)(x)

        x = layers.Reshape((4, 256))(x)
        x = upsample_block(
            x,
            128,
            layers.LeakyReLU(0.2),
            strides=(1),
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        x = upsample_block(
            x,
            64,
            layers.LeakyReLU(0.2),
            strides=(1),
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        x = upsample_block(
            x,
            32,
            layers.LeakyReLU(0.2),
            strides=(1),
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        x = upsample_block(
            x, 1, layers.Activation("tanh"), strides=(1), use_bias=False, use_bn=True
        )
        # At this point, we have an output which has the same shape as the input, (32, 32, 1).
        # We will use a Cropping2D layer to make it (28, 28, 1).
        # x = layers.Cropping1D((2))(x)

        g_model = tf.keras.models.Model(noise, x, name="generator")
        return g_model

    @staticmethod
    def get_generator_dense_model():
        noise = layers.Input(shape=(noise_dim,))
        x = layers.Dense(256, use_bias=False)(noise)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.2)(x)

        # x = layers.Reshape((4, 256))(x)
        x = upsample_dense_block(
            x,
            128,
            layers.LeakyReLU(0.2),
            use_bias=False,
            use_bn=True,
            use_dropout=False,
        )
        x = upsample_dense_block(
            x,
            32,
            layers.LeakyReLU(0.2),
            use_bias=False,
            use_bn=True,
            use_dropout=False,
        )
        x = upsample_dense_block(
            x, 64, layers.Activation("tanh"), use_bias=False, use_bn=True
        )
        # At this point, we have an output which has the same shape as the input, (32, 32, 1).
        # We will use a Cropping2D layer to make it (28, 28, 1).
        # x = layers.Cropping1D((2))(x)

        g_model = tf.keras.models.Model(noise, x, name="generator")
        return g_model

    def forward(self, x):
        x = self.model(x)
        return (
            x if self.final_activation is None else self.final_activation(x)
        )

    @staticmethod
    def get_generator_cont_model():
        noise = layers.Input(shape=(noise_dim,))
        x = layers.Dense(3 * 256, use_bias=False)(noise)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.2)(x)

        x = layers.Reshape((3, 256))(x)
        x = upsample_block(
            x,
            128,
            layers.LeakyReLU(0.2),
            strides=(2),
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        x = upsample_block(
            x,
            32,
            layers.LeakyReLU(0.2),
            strides=(1),
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        x = upsample_block(
            x, 1, layers.Activation("tanh"), strides=(1), use_bias=False, use_bn=True
        )
        # At this point, we have an output which has the same shape as the input, (32, 32, 1).
        # We will use a Cropping2D layer to make it (28, 28, 1).
        # x = layers.Cropping1D((2))(x)

        g_model = tf.keras.models.Model(noise, x, name="generator")
        return g_model


DATA_INPUT = (64, 1)
DATA_INPUT_CONT = (12, 1)


class DiscriminatorBase:
    @staticmethod
    def get_discriminator_model():
        data_input = layers.Input(shape=DATA_INPUT)
        x = layers.ZeroPadding1D((0))(data_input)
        x = conv_block(
            x,
            64,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            use_bias=True,
            activation=layers.LeakyReLU(0.2),
            use_dropout=False,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            128,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=True,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            256,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=True,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            512,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=False,
            drop_value=0.3,
        )

        x = layers.Flatten()(x)
        x = layers.Dropout(0.25)(x)
        x = layers.Dense(1)(x)

        d_model = tf.keras.models.Model(data_input, x, name="discriminator")
        return d_model

    @staticmethod
    def get_discriminator_dense_model():
        data_input = layers.Input(shape=DATA_INPUT)
        # Zero pad the input to make the input images size to (32, 32, 1).
        x = layers.ZeroPadding1D((0))(data_input)
        x = dense_block(
            x,
            64,
            use_bn=False,
            use_bias=True,
            activation=layers.LeakyReLU(0.3),
            use_dropout=False,
            drop_value=0.35,
        )
        x = dense_block(
            x,
            128,
            use_bn=False,
            activation=layers.LeakyReLU(0.3),
            use_bias=True,
            use_dropout=True,
            drop_value=0.35,
        )
        x = dense_block(
            x,
            256,
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=True,
            drop_value=0.35,
        )
        x = dense_block(
            x,
            512,
            use_bn=False,
            activation=layers.LeakyReLU(0.3),
            use_bias=True,
            use_dropout=False,
            drop_value=0.2,
        )

        x = layers.Flatten()(x)
        x = layers.Dropout(0.3)(x)
        x = layers.Dense(1)(x)

        d_model = tf.keras.models.Model(data_input, x, name="discriminator")
        return d_model

    @staticmethod
    def get_discriminator_cont_model():
        data_input = layers.Input(shape=DATA_INPUT_CONT)
        x = layers.ZeroPadding1D((0))(data_input)
        x = conv_block(
            x,
            64,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            use_bias=True,
            activation=layers.LeakyReLU(0.2),
            use_dropout=False,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            128,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=True,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            256,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=True,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            512,
            kernel_size=(5),
            strides=(2),
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=False,
            drop_value=0.3,
        )

        x = layers.Flatten()(x)
        x = layers.Dropout(0.25)(x)
        x = layers.Dense(1)(x)

        d_model = tf.keras.models.Model(data_input, x, name="discriminator")
        return d_model