import itertools

import tensorflow as tf
from keras import backend as K
from tensorflow.keras import layers
from tensorflow.python.framework import ops
from keras.utils.generic_utils import get_custom_objects
from GAN.modules.modelBases import upsample_block, conv_block

noise_dim = 32
DATA_INPUT = (158, 1)


def binary(x):
    return K.relu(K.sign(x))

# def binarize(x):
#     """
#     Clip and binarize tensor using the straight through estimator (STE) for the gradient.
#     """
#     g = tf.get_default_graph()
#
#     with ops.name_scope("Binarized") as name:
#         with g.gradient_override_map({"Sign": "Identity"}):
#             return tf.sign(x)


def make_activator(activations):
    def activator(t):
        slices = tf.unstack(t, axis=1)
        activated = []
        for s, act in zip(slices, itertools.cycle(activations)):
            activated.append(act(s))
        return tf.stack(activated)
    return activator


# def HardTanh(name='HardTanh'):
#     def layer(x, is_training=True):
#         with tf.variable_scope(name, None, [x]):
#             return tf.clip_by_value(x, -1, 1)
#
#     return layer


class GeneratorBaseGEN2:
    @staticmethod
    def get_generator_model():
        get_custom_objects().update({'binary': layers.Activation(binary)})

        noise = layers.Input(shape=(noise_dim,))
        x = layers.Dense(10 * 25, use_bias=False)(noise)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.2)(x)

        x = layers.Reshape((10, 25))(x)
        x = upsample_block(
            x,
            128,
            layers.LeakyReLU(0.2),
            strides=(1),
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        x = upsample_block(
            x,
            64,
            layers.LeakyReLU(0.2),
            strides=(1),
            use_bias=False,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )
        x = upsample_block(
            x,
            32,
            layers.LeakyReLU(0.2),
            strides=1,
            use_bias=False,
            up_size=4,
            use_bn=True,
            padding="same",
            use_dropout=False,
        )

        x = upsample_block(
            x, 1, layers.Activation('tanh'), strides=1, use_bias=False, use_bn=True
        )

        x = layers.Flatten()(x)

        l1 = layers.Dense(2, activation='sigmoid')(x)
        l2 = layers.Dense(156, activation='binary')(x)

        x = layers.Concatenate(axis=1)([l1, l2])

        # At this point, we have an output which has the same shape as the input, (32, 32, 1).
        # We will use a Cropping2D layer to make it (28, 28, 1).
        # x = layers.Cropping1D(1)(x)

        x = layers.Reshape((158, 1))(x)
        g_model = tf.keras.models.Model(noise, x, name="generator")
        return g_model

    def forward(self, x):
        x = self.model(x)
        return (
            x if self.final_activation is None else self.final_activation(x)
        )


class DiscriminatorBaseGEN2:
    @staticmethod
    def get_discriminator_model():
        data_input = layers.Input(shape=DATA_INPUT)
        x = layers.ZeroPadding1D(1)(data_input)
        x = conv_block(
            x,
            16,
            kernel_size=5,
            strides=2,
            use_bn=False,
            use_bias=True,
            activation=layers.LeakyReLU(0.2),
            use_dropout=False,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            32,
            kernel_size=5,
            strides=2,
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=True,
            drop_value=0.3,
        )
        x = conv_block(
            x,
            64,
            kernel_size=5,
            strides=2,
            use_bn=False,
            activation=layers.LeakyReLU(0.2),
            use_bias=True,
            use_dropout=True,
            drop_value=0.3,
        )

        x = layers.Flatten()(x)
        x = layers.Dropout(0.25)(x)
        x = layers.Dense(1)(x)

        d_model = tf.keras.models.Model(data_input, x, name="discriminator")
        return d_model
