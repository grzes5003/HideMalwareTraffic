{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "WGAN_GP.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyPecNTPxEhZUKzl1H5g5RUl"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "f8yOEsKR3cKH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084076863,
     "user_tz": -120,
     "elapsed": 3064,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    }
   },
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LyOFAR-iXCeN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084100926,
     "user_tz": -120,
     "elapsed": 23046,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "53620992-cafe-488f-9181-975c01c8d297"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cNgdfr9M38CS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084502232,
     "user_tz": -120,
     "elapsed": 858,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "3c562a9a-07f5-4f5d-d472-ef7b312be57d"
   },
   "source": [
    "norm_layer=layers.BatchNormalization\n",
    "z_dim = 20\n",
    "final_activation = None\n",
    "noise_dim = 32\n",
    "DATA_INPUT = (64,1)\n",
    "BATCH_SIZE = 512\n",
    "BUFFER_SIZE = 6571\n",
    "\n",
    "%cd /content/drive/MyDrive/colab_data\n",
    "df = pd.read_csv('p2_quic_yt_prepared2.csv')\n",
    "\n",
    "x_all = df.values"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/colab_data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7v7agYiyYOz8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084504272,
     "user_tz": -120,
     "elapsed": 500,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "319c1695-df46-4b1c-b430-f388d4fb6da2"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# x_all_train, x_all_test = train_test_split(\n",
    "#     x_all, test_size=0.25, random_state=42)\n",
    "\n",
    "x_all = df.values\n",
    "# x_all = np.expand_dims(x_all, axis=2)\n",
    "print(x_all.shape)\n",
    "\n",
    "x_all = x_all.reshape(x_all.shape[0], 64, 1).astype('float32')\n",
    "\n",
    "x_all = tf.data.Dataset.from_tensor_slices(x_all).batch(BATCH_SIZE)\n",
    "x_all"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6571, 64)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 64, 1), types: tf.float32>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6nHaopQQ3xF1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084108657,
     "user_tz": -120,
     "elapsed": 356,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    }
   },
   "source": [
    "def conv_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3),\n",
    "    strides=(1),\n",
    "    padding=\"same\",\n",
    "    use_bias=True,\n",
    "    use_bn=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.5,\n",
    "):\n",
    "    x = layers.Conv1D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def upsample_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3),\n",
    "    strides=(1),\n",
    "    up_size=(2),\n",
    "    padding=\"same\",\n",
    "    use_bn=False,\n",
    "    use_bias=True,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.3,\n",
    "):\n",
    "    x = layers.UpSampling1D(up_size)(x)\n",
    "    x = layers.Conv1D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7lRxUpx-TuK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084110755,
     "user_tz": -120,
     "elapsed": 456,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "16617d8c-5c4a-48be-de88-c40257c5ebaa"
   },
   "source": [
    "    def get_generator_model():\n",
    "        noise = layers.Input(shape=(noise_dim,))\n",
    "        x = layers.Dense(4 * 256, use_bias=False)(noise)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "        x = layers.Reshape((4, 256))(x)\n",
    "        x = upsample_block(\n",
    "            x,\n",
    "            128,\n",
    "            layers.LeakyReLU(0.2),\n",
    "            strides=(1),\n",
    "            use_bias=False,\n",
    "            use_bn=True,\n",
    "            padding=\"same\",\n",
    "            use_dropout=False,\n",
    "        )\n",
    "        x = upsample_block(\n",
    "            x,\n",
    "            64,\n",
    "            layers.LeakyReLU(0.2),\n",
    "            strides=(1),\n",
    "            use_bias=False,\n",
    "            use_bn=True,\n",
    "            padding=\"same\",\n",
    "            use_dropout=False,\n",
    "        )\n",
    "        x = upsample_block(\n",
    "            x,\n",
    "            32,\n",
    "            layers.LeakyReLU(0.2),\n",
    "            strides=(1),\n",
    "            use_bias=False,\n",
    "            use_bn=True,\n",
    "            padding=\"same\",\n",
    "            use_dropout=False,\n",
    "        )\n",
    "        x = upsample_block(\n",
    "            x, 1, layers.Activation(\"tanh\"), strides=(1), use_bias=False, use_bn=True\n",
    "        )\n",
    "        # At this point, we have an output which has the same shape as the input, (32, 32, 1).\n",
    "        # We will use a Cropping2D layer to make it (28, 28, 1).\n",
    "        # x = layers.Cropping1D((2))(x)\n",
    "\n",
    "        g_model = tf.keras.models.Model(noise, x, name=\"generator\")\n",
    "        return g_model\n",
    "\n",
    "g_model = get_generator_model()\n",
    "g_model.summary()"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d (UpSampling1D) (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 8, 128)            98304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 128)            512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 64)            24576     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 64)            256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 32)            6144      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32)            128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 64, 1)             96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 1)             4         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 1)             0         \n",
      "=================================================================\n",
      "Total params: 166,884\n",
      "Trainable params: 164,386\n",
      "Non-trainable params: 2,498\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kqhzfIKUabv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084159333,
     "user_tz": -120,
     "elapsed": 325,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "907ef4a0-976c-43f8-be36-dc8fbdca4f22"
   },
   "source": [
    "    def get_discriminator_model():\n",
    "        data_input = layers.Input(shape=DATA_INPUT)\n",
    "        # Zero pad the input to make the input images size to (32, 32, 1).\n",
    "        x = layers.ZeroPadding1D((0))(data_input)\n",
    "        x = conv_block(\n",
    "            x,\n",
    "            64,\n",
    "            kernel_size=(5),\n",
    "            strides=(2),\n",
    "            use_bn=False,\n",
    "            use_bias=True,\n",
    "            activation=layers.LeakyReLU(0.3),\n",
    "            use_dropout=False,\n",
    "            drop_value=0.35,\n",
    "        )\n",
    "        x = conv_block(\n",
    "            x,\n",
    "            128,\n",
    "            kernel_size=(5),\n",
    "            strides=(2),\n",
    "            use_bn=False,\n",
    "            activation=layers.LeakyReLU(0.3),\n",
    "            use_bias=True,\n",
    "            use_dropout=True,\n",
    "            drop_value=0.35,\n",
    "        )\n",
    "        x = conv_block(\n",
    "            x,\n",
    "            256,\n",
    "            kernel_size=(5),\n",
    "            strides=(2),\n",
    "            use_bn=False,\n",
    "            activation=layers.LeakyReLU(0.2),\n",
    "            use_bias=True,\n",
    "            use_dropout=True,\n",
    "            drop_value=0.35,\n",
    "        )\n",
    "        x = conv_block(\n",
    "            x,\n",
    "            512,\n",
    "            kernel_size=(5),\n",
    "            strides=(2),\n",
    "            use_bn=False,\n",
    "            activation=layers.LeakyReLU(0.3),\n",
    "            use_bias=True,\n",
    "            use_dropout=False,\n",
    "            drop_value=0.2,\n",
    "        )\n",
    "\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Dense(1)(x)\n",
    "\n",
    "        d_model = tf.keras.models.Model(data_input, x, name=\"discriminator\")\n",
    "        return d_model\n",
    "d_model = get_discriminator_model()\n",
    "d_model.summary()"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64, 1)]           0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1 (None, 64, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 32, 64)            384       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16, 128)           41088     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 8, 256)            164096    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 4, 512)            655872    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 863,489\n",
      "Trainable params: 863,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6YFwwdULV3sL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635084161808,
     "user_tz": -120,
     "elapsed": 368,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    }
   },
   "source": [
    "class WGAN(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add the gradient penalty to the discriminator loss\n",
    "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
    "\n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 3 extra steps\n",
    "        # as compared to 5 to reduce the training time.\n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator(random_latent_vectors, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwaMoeBcWPg8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635089410743,
     "user_tz": -120,
     "elapsed": 4897255,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "7d88c22d-3292-4b46-f4fd-38b7349b048f"
   },
   "source": [
    "# Instantiate the optimizer for both networks\n",
    "# (learning_rate=0.0002, beta_1=0.5 are recommended)\n",
    "generator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.8\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.8\n",
    ")\n",
    "\n",
    "# Define the loss functions for the discriminator,\n",
    "# which should be (fake_loss - real_loss).\n",
    "# We will add the gradient penalty later to this loss function.\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "\n",
    "# Set the number of epochs for trainining.\n",
    "epochs = 25\n",
    "\n",
    "# # Instantiate the customer `GANMonitor` Keras callback.\n",
    "# cbk = GANMonitor(num_img=3, latent_dim=noise_dim)\n",
    "\n",
    "# Instantiate the WGAN model.\n",
    "wgan = WGAN(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=noise_dim,\n",
    "    discriminator_extra_steps=3,\n",
    ")\n",
    "\n",
    "# Compile the WGAN model.\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n",
    "\n",
    "# Start training the model.\n",
    "wgan.fit(x_all, batch_size=BATCH_SIZE, epochs=epochs)\n",
    "\n",
    "wgan.save_weights('wgan_gp02_wg')\n",
    "d_model.save('wgan_gp_d')\n",
    "g_model.save('wgan_gp_g')\n",
    "\n",
    "random_latent_vectors = tf.random.normal(shape=(7000, noise_dim))\n",
    "generated_images = wgan.generator(random_latent_vectors)\n",
    "\n",
    "import numpy as np\n",
    "arr = np.array(generated_images)\n",
    "arr = np.squeeze(arr)\n",
    "\n",
    "np.savetxt('wgan_gp_data_generated_02.csv', arr, delimiter=',')"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "13/13 [==============================] - 192s 14s/step - d_loss: -0.3669 - g_loss: 1.4353\n",
      "Epoch 2/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -4.1375 - g_loss: 3.6338\n",
      "Epoch 3/25\n",
      "13/13 [==============================] - 182s 14s/step - d_loss: -3.4029 - g_loss: 1.6728\n",
      "Epoch 4/25\n",
      "13/13 [==============================] - 182s 14s/step - d_loss: -2.8899 - g_loss: 0.0203\n",
      "Epoch 5/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.7399 - g_loss: -0.8890\n",
      "Epoch 6/25\n",
      "13/13 [==============================] - 184s 14s/step - d_loss: -2.6643 - g_loss: -1.2217\n",
      "Epoch 7/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.6586 - g_loss: -1.4627\n",
      "Epoch 8/25\n",
      "13/13 [==============================] - 184s 14s/step - d_loss: -2.6535 - g_loss: -1.5838\n",
      "Epoch 9/25\n",
      "13/13 [==============================] - 184s 14s/step - d_loss: -2.6376 - g_loss: -1.3231\n",
      "Epoch 10/25\n",
      "13/13 [==============================] - 184s 14s/step - d_loss: -2.6269 - g_loss: -1.0231\n",
      "Epoch 11/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.6267 - g_loss: -0.4995\n",
      "Epoch 12/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.5850 - g_loss: -0.1770\n",
      "Epoch 13/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.5644 - g_loss: 0.1811\n",
      "Epoch 14/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.5361 - g_loss: 0.5573\n",
      "Epoch 15/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.5166 - g_loss: 0.9225\n",
      "Epoch 16/25\n",
      "13/13 [==============================] - 182s 14s/step - d_loss: -2.4865 - g_loss: 0.9658\n",
      "Epoch 17/25\n",
      "13/13 [==============================] - 184s 14s/step - d_loss: -2.4437 - g_loss: 1.0888\n",
      "Epoch 18/25\n",
      "13/13 [==============================] - 183s 14s/step - d_loss: -2.4288 - g_loss: 1.4292\n",
      "Epoch 19/25\n",
      "13/13 [==============================] - 185s 14s/step - d_loss: -2.4255 - g_loss: 1.6924\n",
      "Epoch 20/25\n",
      "13/13 [==============================] - 184s 14s/step - d_loss: -2.4154 - g_loss: 1.8969\n",
      "Epoch 21/25\n",
      "13/13 [==============================] - 185s 14s/step - d_loss: -2.3875 - g_loss: 1.7437\n",
      "Epoch 22/25\n",
      "13/13 [==============================] - 185s 14s/step - d_loss: -2.3945 - g_loss: 2.1462\n",
      "Epoch 23/25\n",
      "13/13 [==============================] - 185s 14s/step - d_loss: -2.3519 - g_loss: 2.3242\n",
      "Epoch 24/25\n",
      "13/13 [==============================] - 185s 14s/step - d_loss: -2.3798 - g_loss: 2.5100\n",
      "Epoch 25/25\n",
      "13/13 [==============================] - 185s 14s/step - d_loss: -2.3508 - g_loss: 2.4751\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: wgan_gp_d/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: wgan_gp_g/assets\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "_q8XVYBfFPPV",
    "executionInfo": {
     "status": "error",
     "timestamp": 1635008565784,
     "user_tz": -120,
     "elapsed": 397,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "cf2f9dff-b76d-4dae-d891-015ef4d534e7"
   },
   "source": [
    "wgan.save('wgan_gp01')"
   ],
   "execution_count": 109,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.WGAN object at 0x7efc26fb3a90>, because it is not built.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-109-0e0500b5415b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mwgan\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'wgan_gp01'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001B[0m\n\u001B[1;32m   2144\u001B[0m     \u001B[0;31m# pylint: enable=line-too-long\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2145\u001B[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001B[0;32m-> 2146\u001B[0;31m                     signatures, options, save_traces)\n\u001B[0m\u001B[1;32m   2147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2148\u001B[0m   def save_weights(self,\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001B[0m in \u001B[0;36msave_model\u001B[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mgeneric_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSharedObjectSavingScope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001B[0;32m--> 150\u001B[0;31m                             signatures, options, save_traces)\n\u001B[0m\u001B[1;32m    151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001B[0m\n\u001B[1;32m     73\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0msave_traces\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0msave_impl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_skip_serialization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 75\u001B[0;31m       \u001B[0msaving_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_model_input_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0minclude_optimizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saving_utils.py\u001B[0m in \u001B[0;36mraise_model_input_error\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     86\u001B[0m       \u001B[0;34m'set. Usually, input shapes are automatically determined from calling'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m       \u001B[0;34m' `.fit()` or `.predict()`. To manually set the shapes, call '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m       '`model.build(input_shape)`.'.format(model))\n\u001B[0m\u001B[1;32m     89\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Model <__main__.WGAN object at 0x7efc26fb3a90> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling `.fit()` or `.predict()`. To manually set the shapes, call `model.build(input_shape)`."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CIYNMfRiFnBa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635008468343,
     "user_tz": -120,
     "elapsed": 406,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    }
   },
   "source": [
    "wgan.save_weights('wgan_gp01_wg')"
   ],
   "execution_count": 106,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "aeAi31kSnK9P",
    "executionInfo": {
     "status": "error",
     "timestamp": 1635084199982,
     "user_tz": -120,
     "elapsed": 821,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "168f8ebe-23bb-48d0-8fba-88e1ef2826d6"
   },
   "source": [
    "wgan.build()"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-45278e357726>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mwgan\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'wgan' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "VVpIFp64GlNz",
    "executionInfo": {
     "status": "error",
     "timestamp": 1635008631563,
     "user_tz": -120,
     "elapsed": 446,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "4c4bbeb6-46ad-4b69-fd44-3e5c0cae941f"
   },
   "source": [
    "wgan.compute_output_shape(input_shape=(None, 64, 1))"
   ],
   "execution_count": 110,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotImplementedError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-110-eca93a146a68>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mwgan\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_output_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36mcompute_output_shape\u001B[0;34m(self, input_shape)\u001B[0m\n\u001B[1;32m    781\u001B[0m         \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_make_placeholder_like\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 783\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    784\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    785\u001B[0m           raise NotImplementedError(\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    975\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_in_functional_construction_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    976\u001B[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001B[0;32m--> 977\u001B[0;31m                                                 input_list)\n\u001B[0m\u001B[1;32m    978\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m     \u001B[0;31m# Maintains info about the `Layer.call` stack.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_functional_construction_call\u001B[0;34m(self, inputs, args, kwargs, input_list)\u001B[0m\n\u001B[1;32m   1113\u001B[0m       \u001B[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1114\u001B[0m       outputs = self._keras_tensor_symbolic_call(\n\u001B[0;32m-> 1115\u001B[0;31m           inputs, input_masks, args, kwargs)\n\u001B[0m\u001B[1;32m   1116\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1117\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0moutputs\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_keras_tensor_symbolic_call\u001B[0;34m(self, inputs, input_masks, args, kwargs)\u001B[0m\n\u001B[1;32m    846\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeras_tensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mKerasTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_signature\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    847\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 848\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_infer_output_signature\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    850\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_infer_output_signature\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_infer_output_signature\u001B[0;34m(self, inputs, args, kwargs, input_masks)\u001B[0m\n\u001B[1;32m    886\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_build\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m           \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_cast_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 888\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    889\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    890\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    690\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    691\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mconversion_ctx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 692\u001B[0;31m           \u001B[0;32mreturn\u001B[0m \u001B[0mconverted_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    693\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    694\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'ag_error_metadata'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muser_requested\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mconversion\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_allowlisted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_call_unconverted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m   \u001B[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    462\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 463\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    464\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    444\u001B[0m         \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \"\"\"\n\u001B[0;32m--> 446\u001B[0;31m     raise NotImplementedError('When subclassing the `Model` class, you should '\n\u001B[0m\u001B[1;32m    447\u001B[0m                               'implement a `call` method.')\n\u001B[1;32m    448\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: When subclassing the `Model` class, you should implement a `call` method."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dViNebC3JNRn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635009243390,
     "user_tz": -120,
     "elapsed": 2069,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "1334e0cc-cac7-4c68-d591-4936da9cdfd5"
   },
   "source": [
    "d_model.save('wgan_gp_d')"
   ],
   "execution_count": 111,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: wgan_gp_d/assets\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-B8Bj1TJTNP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635009267019,
     "user_tz": -120,
     "elapsed": 4184,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "8abfbbd2-512f-40e7-a1cd-b881cb73382b"
   },
   "source": [
    "g_model.save('wgan_gp_g')"
   ],
   "execution_count": 112,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: wgan_gp_g/assets\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TtfK8yJ0J8nw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635009545420,
     "user_tz": -120,
     "elapsed": 389,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    }
   },
   "source": [
    "random_latent_vectors = tf.random.normal(shape=(2000, noise_dim))\n",
    "generated_images = wgan.generator(random_latent_vectors)"
   ],
   "execution_count": 117,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dz_P1OZlKXdn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635012262528,
     "user_tz": -120,
     "elapsed": 422,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    },
    "outputId": "27795c18-ff64-437b-b0e9-6db2c3b485fd"
   },
   "source": [
    "generated_images.shape"
   ],
   "execution_count": 121,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([2000, 64, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_DrQe4rFKptH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1635009632720,
     "user_tz": -120,
     "elapsed": 394,
     "user": {
      "displayName": "Grzegorz Kuliński",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghkwa1cUwUheG0WpIjL5pe91ZnMgWU2MCxY1qiGdw=s64",
      "userId": "01909219844522326553"
     }
    }
   },
   "source": [
    "import numpy as np\n",
    "arr = np.array(generated_images)\n",
    "arr = np.squeeze(arr)\n",
    "\n",
    "np.savetxt('wgan_gp_data_generated.csv', arr, delimiter=',')"
   ],
   "execution_count": 120,
   "outputs": []
  }
 ]
}